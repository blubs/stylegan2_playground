{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import PIL\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('stylegan2encoder')\n",
    "\n",
    "import dnnlib\n",
    "import pretrained_networks\n",
    "import dnnlib.tflib as tflib\n",
    "from encoder.generator_model import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the images are rotated properly:\n",
    "# https://medium.com/@ageitgey/the-dumb-reason-your-fancy-computer-vision-app-isnt-working-exif-orientation-73166c7d39da\n",
    "def exif_transpose(img):\n",
    "    if not img:\n",
    "        return img\n",
    "    \n",
    "    exif_orientation_tag = 274\n",
    "    \n",
    "    if not hasattr(img, '_getexif'):\n",
    "        return img\n",
    "    if not isinstance(img._getexif(), dict):\n",
    "        return img\n",
    "    if not exif_orientation_tag in img._getexif():\n",
    "        return img\n",
    "    \n",
    "    exif_data = img._getexif()\n",
    "    orientation = exif_data[exif_orientation_tag]\n",
    "    \n",
    "    # Handle orientation:\n",
    "    if orientation == 1:\n",
    "        pass\n",
    "    elif orientation == 2:\n",
    "        img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "    elif orientation == 3:\n",
    "        img = img.rotate(180)\n",
    "    elif orientation == 4:\n",
    "        img = img.rotate(180).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "    elif orientation == 5:\n",
    "        img = img.rotate(-90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "    elif orientation == 6:\n",
    "        img = img.rotate(-90, expand=True)\n",
    "    elif orientation == 7:\n",
    "        img = img.rotate(90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "    elif orientation == 8:\n",
    "        img = img.rotate(90, expand=True)\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_files_with_ext(path, extensions):\n",
    "    files = os.listdir(path)\n",
    "    files = [os.path.join(path,f) for f in files]\n",
    "    files = [f for f in files if os.path.isfile(f)]\n",
    "    files = [f for f in files if f.endswith(tuple(extensions))]\n",
    "    return files\n",
    "\n",
    "def rotate_images(src_path, dest_path):\n",
    "    image_files = get_files_with_ext(src_path, ['.jpg','.png','.jpeg'])\n",
    "\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.makedirs(dest_path)\n",
    "    \n",
    "    for file in image_files:\n",
    "        # Load the image\n",
    "        image = PIL.Image.open(file)\n",
    "        # Fix the orientation using EXIT data\n",
    "        image = exif_transpose(image)\n",
    "        # Save the image\n",
    "        new_file = os.path.splitext(os.path.basename(file))[0]\n",
    "        new_file = new_file + '.png'\n",
    "        new_file = os.path.join(dest_path, new_file)\n",
    "        image.save(new_file)        \n",
    "\n",
    "def align_images(src_path, dest_path):\n",
    "    !python stylegan2encoder/align_images.py $src_path $dest_path\n",
    "    \n",
    "    \n",
    "def resize_images(src_path, dest_path, max_size=1024):\n",
    "    image_files = get_files_with_ext(src_path, ['.jpg','.png','.jpeg'])\n",
    "\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.makedirs(dest_path)\n",
    "    \n",
    "    for file in image_files:\n",
    "        # Load the image\n",
    "        image = PIL.Image.open(file)\n",
    "        # ---------------------------\n",
    "        # Resize the image\n",
    "        # ---------------------------\n",
    "        width, height = image.size\n",
    "        if width > height:\n",
    "            if width > max_size:\n",
    "                new_width = int(max_size)\n",
    "                new_height = int(height * (max_size / width))\n",
    "                image = image.resize((new_width, new_height), PIL.Image.BILINEAR)\n",
    "        else:\n",
    "            if height > max_size:\n",
    "                new_width = int(width * (max_size / height))\n",
    "                new_height = int(max_size)\n",
    "                image = image.resize((new_width, new_height), PIL.Image.BILINEAR)\n",
    "        # ---------------------------\n",
    "        \n",
    "        # Save the image\n",
    "        new_file = os.path.splitext(os.path.basename(file))[0]\n",
    "        new_file = new_file + '.png'\n",
    "        new_file = os.path.join(dest_path, new_file)\n",
    "        image.save(new_file)\n",
    "        \n",
    "def compute_image_latent_vectors(src_path, dest_path):\n",
    "    !python stylegan2encoder/project_images.py $src_path $dest_path --video=True --video-mode=2\n",
    "    \n",
    "\n",
    "def get_latent_vectors(path):\n",
    "    files = get_files_with_ext(path, '.npy')\n",
    "    latent_vectors = [np.load(f) for f in files]\n",
    "    return latent_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_weights):\n",
    "    _G, _D, Gs = pretrained_networks.load_networks(model_weights)\n",
    "    generator = Generator(Gs, batch_size=1, randomize_noise=False)\n",
    "    model = {\n",
    "        'generator': generator\n",
    "    }\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_image(latent_vector, model):\n",
    "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
    "    model['generator'].set_dlatents(latent_vector)\n",
    "    img_array = model['generator'].generate_images()[0]\n",
    "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "    # img = img.resize((256, 256))\n",
    "    return img\n",
    "\n",
    "def show(latent_vector, model):\n",
    "    plt.subplots()\n",
    "    plt.imshow(generate_image(latent_vector, model))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_latents(latent_vector_a, latent_vector_b, t):\n",
    "    return latent_vector_a + (latent_vector_b - latent_vector_a) * t\n",
    "\n",
    "def get_latent_directions(path):\n",
    "    files = get_files_with_ext(path, '.npy')\n",
    "    \n",
    "    latent_directions = {}\n",
    "    \n",
    "    for file in files:\n",
    "        name = os.path.splitext(os.path.basename(file))[0]\n",
    "        latent_directions[name] = np.load(file)\n",
    "    \n",
    "    return latent_directions\n",
    "\n",
    "def move(latent_vector, feature, dist, latent_directions):\n",
    "    return latent_vector + latent_directions[feature] * dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL\n",
    "from ipywidgets import interact, FloatSlider, Layout, FileUpload, \\\n",
    "    Button, Output, Image, HBox, Label\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_image(b):\n",
    "    return PIL.Image.open(io.BytesIO(b))\n",
    "\n",
    "def image_to_bytes(img):\n",
    "    image_data = io.BytesIO()\n",
    "    img.save(image_data, format='PNG')\n",
    "    image_data = image_data.getvalue()\n",
    "    return image_data\n",
    "\n",
    "def update_generated_image(image_widget, model, latent_vector_1, \n",
    "                           latent_vector_2, latent_directions,\n",
    "                           mix=None, key=None, value=None):\n",
    "    \n",
    "    with output:\n",
    "        print('Hello from update: mix: {}, key: {}, value: {}'.format(mix,key,value))\n",
    "        print('\\tMagnitudes: ',update_generated_image.latent_direction_magnitudes)\n",
    "        print('\\tMix: ',update_generated_image.mix)\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # If the state is being updated, store the state\n",
    "    # --------------------------------------------------\n",
    "    if mix is not None:\n",
    "        update_generated_image.mix = mix\n",
    "\n",
    "    if key is not None and value is not None:\n",
    "        update_generated_image.latent_direction_magnitudes[key] = value\n",
    "        \n",
    "    mix = update_generated_image.mix\n",
    "    latent_direction_magnitudes = update_generated_image.latent_direction_magnitudes\n",
    "    # --------------------------------------------------\n",
    "        \n",
    "    # --------------------------------------------------\n",
    "    # Generate the new latent vector\n",
    "    # --------------------------------------------------\n",
    "    latent = mix_latents(latent_vector_1, latent_vector_2, mix)\n",
    "    \n",
    "    for key in latent_directions:\n",
    "        if key not in latent_direction_magnitudes:\n",
    "            continue\n",
    "        \n",
    "        value = latent_direction_magnitudes[key]\n",
    "        latent = move(latent, key, value, latent_directions)\n",
    "    # --------------------------------------------------\n",
    "    \n",
    "    np.save('generated_latent.npy',latent)\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Generate the new image\n",
    "    # --------------------------------------------------\n",
    "    image = generate_image(latent, model)\n",
    "    image_data = image_to_bytes(image)\n",
    "    image_widget.value = image_data\n",
    "    # --------------------------------------------------\n",
    "    \n",
    "def make_mix_latents_slider(image_widget, model, latent_vector_1, latent_vector_2, latent_directions):\n",
    "    start_value = 0.5\n",
    "    min_value = 0.0\n",
    "    max_value = 1.0\n",
    "    value_step = 0.01\n",
    "    \n",
    "    label = 'Mix'\n",
    "    layout = Layout(width='80%', height='20px')\n",
    "    # If False, image will only be updated on mouse release events.\n",
    "    # If True, image will be updated continuously (though there is significant delay)\n",
    "    continuous_update = False\n",
    "    \n",
    "    update_func = lambda x : update_generated_image(image_widget,model, \n",
    "                                                    latent_vector_1,latent_vector_2,\n",
    "                                                    latent_directions,mix=x)\n",
    "    \n",
    "    slider = FloatSlider(min=min_value, max=max_value, \n",
    "                         step=value_step, value=start_value, \n",
    "                         description=label, layout=layout, \n",
    "                         continuous_update=continuous_update)\n",
    "    interact(update_func, x=slider)\n",
    "    \n",
    "def make_latent_direction_slider(image_widget, model, latent_vector_1, latent_vector_2, feature, latent_directions):\n",
    "    start_value = 0.0\n",
    "    min_value = -20.0\n",
    "    max_value = 20.0\n",
    "    value_step = 0.01\n",
    "    \n",
    "    label = str(feature)\n",
    "    # Remove prefix to make the label shorter\n",
    "    label = label.replace('emotion_','')\n",
    "    layout = Layout(width='80%', height='20px')\n",
    "    # If False, image will only be updated on mouse release events.\n",
    "    # If True, image will be updated continuously (though there is significant delay)\n",
    "    continuous_update = False\n",
    "    \n",
    "    update_func = lambda x : update_generated_image(image_widget,model, \n",
    "                                                latent_vector_1,latent_vector_2,\n",
    "                                                latent_directions,\n",
    "                                                key=feature, value=x)\n",
    "\n",
    "    slider = FloatSlider(min=min_value, max=max_value, \n",
    "                         step=value_step, value=start_value, \n",
    "                         description=label, layout=layout, \n",
    "                         continuous_update=continuous_update)\n",
    "    interact(update_func, x=slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Run this section to run this on images in 'raw_images'\n",
    "# ---------------------------------------------------------\n",
    "# # Verify that images are upright\n",
    "# rotate_images('raw_images','rotated_images')\n",
    "\n",
    "# # Crop to faces in images\n",
    "# align_images('rotated_images','aligned_images')\n",
    "\n",
    "# # Make images be no bigger than 1024\n",
    "# resize_images('aligned_images','resized_images',1024)\n",
    "\n",
    "# # Compute latent representation of images\n",
    "# compute_image_latent_vectors('resized_images','processed_images')\n",
    "\n",
    "# # Load the latent representations\n",
    "# latent_reps = get_latent_vectors('processed_images')\n",
    "\n",
    "# stylegan2weights = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n",
    "# model = load_model(stylegan2weights)\n",
    "\n",
    "# # Draw the latent\n",
    "# show(latent_reps[0], model)\n",
    "\n",
    "# # Load the latent direction basis vectors\n",
    "# latent_directions = get_latent_directions('stylegan2encoder/latent_directions')\n",
    "# print('-- Available Latent Directions --')\n",
    "# for k in latent_directions.keys():\n",
    "#     print('\\t',k)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Run this section to run this on precomputed latent vectors\n",
    "# ---------------------------------------------------------\n",
    "# Load the latent representations\n",
    "latent_reps = get_latent_vectors('latent_representations')\n",
    "\n",
    "stylegan2weights = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n",
    "model = load_model(stylegan2weights)\n",
    "\n",
    "# Load the latent direction basis vectors\n",
    "latent_directions = get_latent_directions('stylegan2encoder/latent_directions')\n",
    "print('-- Available Latent Directions --')\n",
    "for k in latent_directions.keys():\n",
    "    print('\\t',k)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Test the latents created above:\n",
    "# ---------------------------------------------------------\n",
    "# # Draw the latent\n",
    "# show(latent_reps[0], model)\n",
    "# show(latent_reps[1], model)\n",
    "\n",
    "# # Mix the first two latents\n",
    "# show(mix_latents(latent_reps[0],latent_reps[1], 0.5), model)\n",
    "\n",
    "# # Load the latent direction basis vectors\n",
    "# latent_directions = get_latent_directions('stylegan2encoder/latent_directions')\n",
    "# print('-- Available Latent Directions --')\n",
    "# for k in latent_directions.keys():\n",
    "#     print('\\t',k)\n",
    "\n",
    "# # Make them happy\n",
    "# show(move(latent_reps[0], 'smile', -2.0, latent_directions), model)\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = Output()\n",
    "layout = Layout(width='300px')\n",
    "\n",
    "image_widget_1 = Image(layout=layout)\n",
    "image_widget_2 = Image(layout=layout)\n",
    "image_widget_3 = Image(layout=layout)\n",
    "images_container = HBox([image_widget_1, image_widget_3, image_widget_2])\n",
    "display(images_container)\n",
    "\n",
    "\n",
    "latent_1 = latent_reps[0]\n",
    "latent_2 = latent_reps[1]\n",
    "\n",
    "# Generated latents are saved here, you can use them, too:\n",
    "# latent_1 = np.load('generated_latent.npy')\n",
    "\n",
    "\n",
    "# np.save('generated_latent.npy',latent)\n",
    "\n",
    "image_widget_1.value = image_to_bytes(generate_image(latent_1, model))\n",
    "image_widget_2.value = image_to_bytes(generate_image(latent_2, model))\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Set the initial state \n",
    "# --------------------------------------------------\n",
    "update_generated_image.mix = 0.5\n",
    "update_generated_image.latent_direction_magnitudes = {}\n",
    "# --------------------------------------------------\n",
    "make_mix_latents_slider(image_widget_3, model, latent_1, latent_2, latent_directions)\n",
    "for k in latent_directions:\n",
    "    make_latent_direction_slider(image_widget_3, model, latent_1, latent_2, k, latent_directions)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# File Uploaders\n",
    "# --------------------------------\n",
    "# This file uploader works, but while developing, we lost the ability to get new latent vecs\n",
    "# (Thanks, Google Drive setting a rate limit on the amount of times model weights may be downloaded)\n",
    "# So I had to abandon the use of this.\n",
    "# --\n",
    "# The only thing left to do is to compute the latent vectors of the loaded images,\n",
    "# and use those latent vectors for the slider values.\n",
    "# --------------------------------\n",
    "def on_value_changed(change):\n",
    "    with output:\n",
    "        filename = list(change['new'].keys())[0]\n",
    "        image_data = change['new'][filename]['content']\n",
    "        print('Uploaded file: ',filename)\n",
    "        image = bytes_to_image(image_data)\n",
    "        \n",
    "        # Orient the image properly:\n",
    "        image = exif_transpose(image)\n",
    "        image_data = image_to_bytes(image)\n",
    "                \n",
    "        if len(image_widget_1.value) == 0:\n",
    "            image_widget_1.value = image_data\n",
    "        elif len(image_widget_2.value) == 0:\n",
    "            image_widget_2.value = image_data\n",
    "        else:\n",
    "            image_widget_1.value = image_widget_2.value\n",
    "            image_widget_2.value = image_data\n",
    "        \n",
    "        # If we have both images, update the generated image:\n",
    "        if len(image_widget_1.value) > 0 and len(image_widget_2.value) > 0:            \n",
    "            image_1 = bytes_to_image(image_widget_1.value)\n",
    "            image_2 = bytes_to_image(image_widget_2.value)\n",
    "    \n",
    "            i1_width, i1_height = image_1.size\n",
    "            image_2_resized = image_2.resize((i1_width,i1_height), PIL.Image.LANCZOS)\n",
    "            # image_1.paste(image_2_resized, None, image_2_resized)\n",
    "            \n",
    "            image_3 = PIL.Image.blend(image_1, image_2_resized, 0.5)\n",
    "            image_widget_3.value = image_to_bytes(image_3)\n",
    "\n",
    "\n",
    "uploader = FileUpload()\n",
    "uploader.observe(on_value_changed, names='value')\n",
    "display(uploader)\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "# --------------------------------\n",
    "# button\n",
    "# --------------------------------\n",
    "# This button implementation is a working stub.\n",
    "# Not sure what we were planning on using it for, \n",
    "# but here's a button, if you ever need one.\n",
    "# --------------------------------\n",
    "# button = Button(description='Click Me!')\n",
    "\n",
    "# display(button, output)\n",
    "\n",
    "# def on_button_clicked(button):\n",
    "#     with output:\n",
    "#         print('Button clicked')\n",
    "\n",
    "# button.on_click(on_button_clicked)\n",
    "# --------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
